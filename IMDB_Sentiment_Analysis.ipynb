{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEPexTIy1FD+NF0Fxszhje",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshadj1611/IMDB-Reviews---Sentimental-Analysis/blob/main/IMDB_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the library wordninja"
      ],
      "metadata": {
        "id": "L8gd6ukN9f8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordninja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqZP4qk8pyAM",
        "outputId": "23e332f3-5f96-428c-d6a2-38ebdc261a41"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wordninja\n",
            "  Downloading wordninja-2.0.0.tar.gz (541 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 36.3 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30 kB 41.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 51 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 102 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 112 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 122 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 143 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 163 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 194 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 204 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 215 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 225 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 235 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 245 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 256 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 266 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 276 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 286 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 296 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 307 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 317 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 327 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 337 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 348 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 358 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 368 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 378 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 389 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 399 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 409 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 419 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 430 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 440 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 450 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 460 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 471 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 481 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 491 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 501 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 512 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 522 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 532 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 541 kB 13.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wordninja\n",
            "  Building wheel for wordninja (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordninja: filename=wordninja-2.0.0-py3-none-any.whl size=541551 sha256=c35da82c404afbcb2689a7239484b10531eeef74c78243b3f3c9ecd01239a72d\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/3f/eb/a2692e3d2b9deb1487b09ba4967dd6920bd5032bfd9ff7acfc\n",
            "Successfully built wordninja\n",
            "Installing collected packages: wordninja\n",
            "Successfully installed wordninja-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required libraries"
      ],
      "metadata": {
        "id": "dQTbWE0u9mar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from string import punctuation\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "dzzEuQVDWHf6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The datasets we are going to use (Downloaded from Kaggle)"
      ],
      "metadata": {
        "id": "A06lFzKTGjbQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ltr0xC3EVqDV"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"/content/Train.csv\")\n",
        "test = pd.read_csv(\"/content/Test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IngQRWfcWVZE",
        "outputId": "79157d97-3297-4ad5-b16d-ee60e4821d46"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-35dd36e3-3e9b-4579-a1cc-fda0844118c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When I put this movie in my DVD player, and sa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why do people who do not know what a particula...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Even though I have great interest in Biblical ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35dd36e3-3e9b-4579-a1cc-fda0844118c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35dd36e3-3e9b-4579-a1cc-fda0844118c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35dd36e3-3e9b-4579-a1cc-fda0844118c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  I grew up (b. 1965) watching and loving the Th...      0\n",
              "1  When I put this movie in my DVD player, and sa...      0\n",
              "2  Why do people who do not know what a particula...      0\n",
              "3  Even though I have great interest in Biblical ...      0\n",
              "4  Im a die hard Dads Army fan and nothing will e...      1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RuMqaTi6oky4",
        "outputId": "b0dae3cc-b891-4904-805c-4f826f5b9b8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ed967406-9be0-4408-8046-9dc83f062003\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I always wrote this series off as being a comp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This movie was so poorly written and directed ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The most interesting thing about Miryang (Secr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed967406-9be0-4408-8046-9dc83f062003')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed967406-9be0-4408-8046-9dc83f062003 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed967406-9be0-4408-8046-9dc83f062003');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  I always wrote this series off as being a comp...      0\n",
              "1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0\n",
              "2  This movie was so poorly written and directed ...      0\n",
              "3  The most interesting thing about Miryang (Secr...      1\n",
              "4  when i first read about \"berlin am meer\" i did...      0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking if there are null values"
      ],
      "metadata": {
        "id": "Yq5BxGtrGqZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_UMpdNMnnW1",
        "outputId": "abb7ed09-5dad-47a1-af62-ceee43214886"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RIr7FDmnnlk",
        "outputId": "32b63f8b-972a-46eb-8aa5-a6b4e09b6c6f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning the data "
      ],
      "metadata": {
        "id": "tqw8DQoWGzg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Converting every word in lower text\n",
        "train['text'] = train['text'].apply(lambda x : str.lower(x))\n",
        "test['text'] = test['text'].apply(lambda x : str.lower(x))"
      ],
      "metadata": {
        "id": "D50DrT8kXBj5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Cleaning if any url present in the dataset\n",
        "def clean_url(text):\n",
        "    text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)\n",
        "    text = text.strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "882_KJMdXBl-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x : clean_url(x))\n",
        "test['text'] = test['text'].apply(lambda x : clean_url(x))"
      ],
      "metadata": {
        "id": "QH25Rl5EXBoA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Cleaning the dataset further\n",
        "def clean(text):\n",
        "    text = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", text) #remove mentions or tags\n",
        "    text = re.sub('<br\\s?\\/>|<br>', \" \", text) # remove br tags\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n",
        "    \n",
        "    text = re.sub(\" +\", \" \", text) #remove extra white spaces\n",
        "    text = re.sub(\"[0-9]+\", \"\", text) #remove in numeric data\n",
        "    text = re.sub(\"[^A-Za-z0-9_. ]+\",\"\",text) #remove any other characters other than A-Z a-z 0-9. \n",
        "    return text    "
      ],
      "metadata": {
        "id": "VV9lPoS6XBpz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x : clean(x))\n",
        "test['text'] = test['text'].apply(lambda x : clean(x))"
      ],
      "metadata": {
        "id": "WIw_4pjuXBr8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Removing blank spaces\n",
        "def blank_space(text):\n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    \n",
        "    return text"
      ],
      "metadata": {
        "id": "0XVj1zhqXBvP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x : blank_space(x))\n",
        "test['text'] = test['text'].apply(lambda x : blank_space(x))"
      ],
      "metadata": {
        "id": "GVOc_ziyWVbi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## If two English words get joined from the above step, we will seperate them in this step by using wordninja package\n",
        "import wordninja \n",
        "def ninja(text):\n",
        "    text = wordninja.split(text)\n",
        "    text = \" \".join(text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "F0lXCA7glNML"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x : ninja(x))\n",
        "test['text'] = test['text'].apply(lambda x : ninja(x))"
      ],
      "metadata": {
        "id": "i2QgBJt3lNaH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing stop words"
      ],
      "metadata": {
        "id": "vMJTGODAHCXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "def remove_stopwords(text):\n",
        "    stopword = stopwords.words('english')\n",
        "    \n",
        "    text = [word for word in text.split() if not word in stopword]\n",
        "    text = \" \".join(text)\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IGj3tn1WVdG",
        "outputId": "b6dfcb2b-6088-4508-e1f0-02335fed380f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x : remove_stopwords(x))\n",
        "test['text'] = test['text'].apply(lambda x : remove_stopwords(x))"
      ],
      "metadata": {
        "id": "Nm38flTtWVfT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## tokenizer \n",
        "nltk.download('punkt')\n",
        "def tokens(text):\n",
        "    text = word_tokenize(text)\n",
        "    text = \" \".join(text)\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKNPcCl3WVim",
        "outputId": "208eda60-0361-4ea4-fbc9-4c7253f979d1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x : tokens(x))\n",
        "test['text'] = test['text'].apply(lambda x : tokens(x))"
      ],
      "metadata": {
        "id": "4wn8TJmhX_EA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download('state_union')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnsy22WUX_Om",
        "outputId": "78d7199d-fa7a-4db3-f2c3-4f34e6e08f64"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/state_union.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to get Parts Of Speech of the words"
      ],
      "metadata": {
        "id": "A7QW3ynoHKVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a function to get the parts of speech of the words.\n",
        "## It gives us the context in which the word has been used.\n",
        "## For example: 'watch' can be used as a verb but 'watch' as in wrist watch is a noun\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import state_union\n",
        "\n",
        "training = state_union.raw(\"2005-GWBush.txt\")\n",
        "tokenizer = nltk.tokenize.punkt.PunktSentenceTokenizer(training)\n",
        "\n",
        "def get_word_pos(word):\n",
        "    \n",
        "    sample = word\n",
        "    \n",
        "    tokenized = tokenizer.tokenize(sample)\n",
        "#     print(tokenized)\n",
        "    \n",
        "    \n",
        "    for i in tokenized:\n",
        "        words = nltk.word_tokenize(i)\n",
        "        tagged = nltk.pos_tag(words)\n",
        "#         print(tagged)\n",
        "        \n",
        "    for letter in tagged:\n",
        "    #print(letter[1])\n",
        "        if letter[1].startswith('J'):\n",
        "            return wordnet.ADJ\n",
        "        elif letter[1].startswith('V'):\n",
        "            return wordnet.VERB\n",
        "        elif letter[1].startswith('N'):\n",
        "            return wordnet.NOUN\n",
        "        elif letter[1].startswith('R'):\n",
        "            return wordnet.ADV\n",
        "        else:\n",
        "            return wordnet.NOUN"
      ],
      "metadata": {
        "id": "KOkmAEbIX_Qn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performing process of lemmatization"
      ],
      "metadata": {
        "id": "Oh5YKemBHUIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize(text):\n",
        "    \n",
        "    lemmatized_text = []\n",
        "    \n",
        "    tokens = word_tokenize(text)\n",
        "#     print(tokens)\n",
        "    \n",
        "    for word in tokens:\n",
        "        \n",
        "        lemmatized_text.append(lemmatizer.lemmatize(word, get_word_pos(word)))\n",
        "\n",
        "    return \" \".join(lemmatized_text)"
      ],
      "metadata": {
        "id": "pZBK8ccRX_Sk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x : lemmatize(x))\n",
        "test['text'] = test['text'].apply(lambda x : lemmatize(x))"
      ],
      "metadata": {
        "id": "5PZkcVnoX_UY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train['text'].copy()\n",
        "x_test = test['text'].copy()\n",
        "\n",
        "y_train = train['label'].copy()\n",
        "y_test = test['label'].copy()"
      ],
      "metadata": {
        "id": "LfQ6efFhX_XL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umoTZTSXX_ZI",
        "outputId": "f2ad6488-1b55-4631-f97f-8a4107602e50"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    grow b watch love thunderbird mate school watc...\n",
              "1    put movie dvd player coke chip expectation hop...\n",
              "2    people know particular time past like feel nee...\n",
              "3    even though great interest biblical movie bore...\n",
              "4    im die hard dad army fan nothing ever change g...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train: \",x_train.shape,y_train.shape,\"Test: \",(x_test.shape,y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7QjSCuAX_bI",
        "outputId": "9f874013-8608-42c3-f61c-457362502177"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:  (40000,) (40000,) Test:  ((5000,), (5000,))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing TfidVectorizer"
      ],
      "metadata": {
        "id": "5w-uI9BUHboq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Term frequency-inverse document frequency is a text vectorizer that transforms the text into a usable vector\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
        "tfidfconverter = TfidfVectorizer(max_features=4000, min_df=1, max_df=0.9, ngram_range=(1,1))  \n",
        "X_train = tfidfconverter.fit_transform(x_train)\n",
        "X_test = tfidfconverter.transform(x_test)"
      ],
      "metadata": {
        "id": "yo0gH_6HX_dq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing classification models"
      ],
      "metadata": {
        "id": "qNrIHp_PHidn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine"
      ],
      "metadata": {
        "id": "coUSYouJB1rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Support vector machines use support vectors to train and then classify the new data point into particular category\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel= \"linear\", random_state=0)\n",
        "classifier.fit(X_train,y_train)\n"
      ],
      "metadata": {
        "id": "pE4NWNB6X_fU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f594ef4d-42e6-4489-9c4f-766c1818c5c7"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear', random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred=classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "JwUQWi2Bi_lk"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        " \n",
        "print(confusion_matrix(y_test,y_test_pred))  \n",
        "print(classification_report(y_test,y_test_pred))  \n",
        "print(accuracy_score(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECFj8JV_i_3n",
        "outputId": "d106f19b-addd-4133-b9be-05a0aef8c427"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2175  320]\n",
            " [ 257 2248]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88      2495\n",
            "           1       0.88      0.90      0.89      2505\n",
            "\n",
            "    accuracy                           0.88      5000\n",
            "   macro avg       0.88      0.88      0.88      5000\n",
            "weighted avg       0.88      0.88      0.88      5000\n",
            "\n",
            "0.8846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "J5f3VD2gI68a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)  \n",
        "text_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlcoLFQ7i_5v",
        "outputId": "1a9381ca-ca16-4132-9e5f-196d69823b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = text_classifier.predict(X_test)\n",
        " \n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        " \n",
        "print(confusion_matrix(y_test,predictions))  \n",
        "print(classification_report(y_test,predictions))  \n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax_gu8mOi_8H",
        "outputId": "accae88c-94fa-4e58-b628-ac39e1173b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2130  365]\n",
            " [ 364 2141]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85      2495\n",
            "           1       0.85      0.85      0.85      2505\n",
            "\n",
            "    accuracy                           0.85      5000\n",
            "   macro avg       0.85      0.85      0.85      5000\n",
            "weighted avg       0.85      0.85      0.85      5000\n",
            "\n",
            "0.8542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "kEtxOdH6I-hI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Logistic regression is a process of modeling the probability of a discrete outcome given an input variable\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(max_iter=3500,solver='saga')"
      ],
      "metadata": {
        "id": "UXJuMfxPi_-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI7mJOYejAAE",
        "outputId": "904ce42c-1cc3-473a-82c7-af5304055533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=3500, solver='saga')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred=clf.predict(X_test)"
      ],
      "metadata": {
        "id": "wjTOLzyxjACL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test,y_test_pred))  \n",
        "print(classification_report(y_test,y_test_pred))  \n",
        "print(accuracy_score(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV5suZHBjAFm",
        "outputId": "9e00a0df-ea85-4440-a136-797f28812a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2169  326]\n",
            " [ 256 2249]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88      2495\n",
            "           1       0.87      0.90      0.89      2505\n",
            "\n",
            "    accuracy                           0.88      5000\n",
            "   macro avg       0.88      0.88      0.88      5000\n",
            "weighted avg       0.88      0.88      0.88      5000\n",
            "\n",
            "0.8836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN classification"
      ],
      "metadata": {
        "id": "f7IWJrwMIMmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## KNN is a supervised classification algorithm that classifies new data points based on the nearest data points\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=500, metric=\"minkowski\", p =2 )\n",
        "classifier.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA9Bgd-cIRv-",
        "outputId": "b8f17c34-34eb-4b38-9168-20a35bbc70f7"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=500)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred=classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "uQ_GL5ZyIZ6b"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(confusion_matrix(y_test,y_test_pred))  \n",
        "print(classification_report(y_test,y_test_pred))  \n",
        "print(accuracy_score(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhbALJ1oIa8z",
        "outputId": "8e3624d4-cfba-4238-b901-ba3d90eac94a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2132  363]\n",
            " [ 516 1989]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83      2495\n",
            "           1       0.85      0.79      0.82      2505\n",
            "\n",
            "    accuracy                           0.82      5000\n",
            "   macro avg       0.83      0.82      0.82      5000\n",
            "weighted avg       0.83      0.82      0.82      5000\n",
            "\n",
            "0.8242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "By implementing Support Vector Machine we have achieved an accuracy of 0.8846 which is slightly better (or almost similar) as compared to Logistic Regression Classifier which has an accuracy of 0.8836\n",
        "Random forest classifiers performance is also good. Its accuracy is 0.8542\n",
        "K Nearest Neighbour classfier has lowest accuracy as compared to other classifiers in this case\n"
      ],
      "metadata": {
        "id": "c2rZk-H1I5Qr"
      }
    }
  ]
}