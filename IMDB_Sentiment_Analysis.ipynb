{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4oL93s0Gx+OEsnItR52tY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshadj1611/IMDB-Reviews---Sentimental-Analysis/blob/main/IMDB_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the library wordninja"
      ],
      "metadata": {
        "id": "L8gd6ukN9f8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordninja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqZP4qk8pyAM",
        "outputId": "560e826d-cc2b-482e-ba83-6c499a1978ae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wordninja\n",
            "  Downloading wordninja-2.0.0.tar.gz (541 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 1.6 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 3.0 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 51 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 102 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 112 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 122 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 143 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 163 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 194 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 204 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 215 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 225 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 235 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 245 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 256 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 266 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 276 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 286 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 296 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 307 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 317 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 327 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 337 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 348 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 358 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 368 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 378 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 389 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 399 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 409 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 419 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 430 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 440 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 450 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 460 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 471 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 481 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 491 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 501 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 512 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 522 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 532 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 541 kB 6.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wordninja\n",
            "  Building wheel for wordninja (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordninja: filename=wordninja-2.0.0-py3-none-any.whl size=541551 sha256=0b9e9ea1991fb3fccbaff691edf63bcf05e746627e2fefc921c426b6e75f034e\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/3f/eb/a2692e3d2b9deb1487b09ba4967dd6920bd5032bfd9ff7acfc\n",
            "Successfully built wordninja\n",
            "Installing collected packages: wordninja\n",
            "Successfully installed wordninja-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required libraries"
      ],
      "metadata": {
        "id": "dQTbWE0u9mar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from string import punctuation\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "dzzEuQVDWHf6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The datasets we are going to use (Downloaded from Kaggle)"
      ],
      "metadata": {
        "id": "A06lFzKTGjbQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ltr0xC3EVqDV"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"/content/Train.csv\")\n",
        "test = pd.read_csv(\"/content/Test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IngQRWfcWVZE",
        "outputId": "f99fefa2-0232-4390-fa95-f7a41fe3d3da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6a45ac3a-c463-4a6a-add6-c1fe87020812\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When I put this movie in my DVD player, and sa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why do people who do not know what a particula...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Even though I have great interest in Biblical ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a45ac3a-c463-4a6a-add6-c1fe87020812')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a45ac3a-c463-4a6a-add6-c1fe87020812 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a45ac3a-c463-4a6a-add6-c1fe87020812');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  I grew up (b. 1965) watching and loving the Th...      0\n",
              "1  When I put this movie in my DVD player, and sa...      0\n",
              "2  Why do people who do not know what a particula...      0\n",
              "3  Even though I have great interest in Biblical ...      0\n",
              "4  Im a die hard Dads Army fan and nothing will e...      1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RuMqaTi6oky4",
        "outputId": "587f7941-9f16-4db7-9d7b-94f5bc1b704d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b44c8283-6418-4f30-b53b-f166a970909a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I always wrote this series off as being a comp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This movie was so poorly written and directed ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The most interesting thing about Miryang (Secr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b44c8283-6418-4f30-b53b-f166a970909a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b44c8283-6418-4f30-b53b-f166a970909a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b44c8283-6418-4f30-b53b-f166a970909a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  I always wrote this series off as being a comp...      0\n",
              "1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0\n",
              "2  This movie was so poorly written and directed ...      0\n",
              "3  The most interesting thing about Miryang (Secr...      1\n",
              "4  when i first read about \"berlin am meer\" i did...      0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking if there are null values"
      ],
      "metadata": {
        "id": "Yq5BxGtrGqZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_UMpdNMnnW1",
        "outputId": "2215afc7-5e9b-424f-e85f-26e2c61938fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RIr7FDmnnlk",
        "outputId": "216509fb-b939-474e-986a-baf706c972fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning the data "
      ],
      "metadata": {
        "id": "tqw8DQoWGzg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Converting every word in lower text\n",
        "train['text'] = train['text'].apply(lambda x : str.lower(x))\n",
        "test['text'] = test['text'].apply(lambda x : str.lower(x))"
      ],
      "metadata": {
        "id": "D50DrT8kXBj5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Cleaning if any url present in the dataset\n",
        "def clean_url(text):\n",
        "    text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)\n",
        "    text = text.strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "882_KJMdXBl-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x : clean_url(x))\n",
        "test['text'] = test['text'].apply(lambda x : clean_url(x))"
      ],
      "metadata": {
        "id": "QH25Rl5EXBoA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Cleaning the dataset further\n",
        "def clean(text):\n",
        "    text = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", text) #remove mentions or tags\n",
        "    text = re.sub('<br\\s?\\/>|<br>', \" \", text) # remove br tags\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n",
        "    \n",
        "    text = re.sub(\" +\", \" \", text) #remove extra white spaces\n",
        "    text = re.sub(\"[0-9]+\", \"\", text) #remove in numeric data\n",
        "    text = re.sub(\"[^A-Za-z0-9_. ]+\",\"\",text) #remove any other characters other than A-Z a-z 0-9. \n",
        "    return text    "
      ],
      "metadata": {
        "id": "VV9lPoS6XBpz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x : clean(x))\n",
        "test['text'] = test['text'].apply(lambda x : clean(x))"
      ],
      "metadata": {
        "id": "WIw_4pjuXBr8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Removing blank spaces\n",
        "def blank_space(text):\n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    \n",
        "    return text"
      ],
      "metadata": {
        "id": "0XVj1zhqXBvP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x : blank_space(x))\n",
        "test['text'] = test['text'].apply(lambda x : blank_space(x))"
      ],
      "metadata": {
        "id": "GVOc_ziyWVbi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## If two English words get joined from the above step, we will seperate them in this step by using wordninja package\n",
        "import wordninja \n",
        "def ninja(text):\n",
        "    text = wordninja.split(text)\n",
        "    text = \" \".join(text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "F0lXCA7glNML"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x : ninja(x))\n",
        "test['text'] = test['text'].apply(lambda x : ninja(x))"
      ],
      "metadata": {
        "id": "i2QgBJt3lNaH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing stop words"
      ],
      "metadata": {
        "id": "vMJTGODAHCXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "def remove_stopwords(text):\n",
        "    stopword = stopwords.words('english')\n",
        "    \n",
        "    text = [word for word in text.split() if not word in stopword]\n",
        "    text = \" \".join(text)\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IGj3tn1WVdG",
        "outputId": "802cebcf-72da-4699-c505-3bc7fe903c14"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x : remove_stopwords(x))\n",
        "test['text'] = test['text'].apply(lambda x : remove_stopwords(x))"
      ],
      "metadata": {
        "id": "Nm38flTtWVfT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## tokenizer \n",
        "nltk.download('punkt')\n",
        "def tokens(text):\n",
        "    text = word_tokenize(text)\n",
        "    text = \" \".join(text)\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKNPcCl3WVim",
        "outputId": "4f4e9468-79c8-4b4f-d5b2-302cd9052d83"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x : tokens(x))\n",
        "test['text'] = test['text'].apply(lambda x : tokens(x))"
      ],
      "metadata": {
        "id": "4wn8TJmhX_EA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download('state_union')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnsy22WUX_Om",
        "outputId": "8bca2568-9c20-4e28-bfc6-74ee7405c2bf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/state_union.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to get Parts Of Speech of the words"
      ],
      "metadata": {
        "id": "A7QW3ynoHKVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a function to get the parts of speech of the words.\n",
        "## It gives us the context in which the word has been used.\n",
        "## For example: 'watch' can be used as a verb but 'watch' as in wrist watch is a noun\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import state_union\n",
        "\n",
        "training = state_union.raw(\"2005-GWBush.txt\")\n",
        "tokenizer = nltk.tokenize.punkt.PunktSentenceTokenizer(training)\n",
        "\n",
        "def get_word_pos(word):\n",
        "    \n",
        "    sample = word\n",
        "    \n",
        "    tokenized = tokenizer.tokenize(sample)\n",
        "#     print(tokenized)\n",
        "    \n",
        "    \n",
        "    for i in tokenized:\n",
        "        words = nltk.word_tokenize(i)\n",
        "        tagged = nltk.pos_tag(words)\n",
        "#         print(tagged)\n",
        "        \n",
        "    for letter in tagged:\n",
        "    #print(letter[1])\n",
        "        if letter[1].startswith('J'):\n",
        "            return wordnet.ADJ\n",
        "        elif letter[1].startswith('V'):\n",
        "            return wordnet.VERB\n",
        "        elif letter[1].startswith('N'):\n",
        "            return wordnet.NOUN\n",
        "        elif letter[1].startswith('R'):\n",
        "            return wordnet.ADV\n",
        "        else:\n",
        "            return wordnet.NOUN"
      ],
      "metadata": {
        "id": "KOkmAEbIX_Qn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performing process of lemmatization"
      ],
      "metadata": {
        "id": "Oh5YKemBHUIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize(text):\n",
        "    \n",
        "    lemmatized_text = []\n",
        "    \n",
        "    tokens = word_tokenize(text)\n",
        "#     print(tokens)\n",
        "    \n",
        "    for word in tokens:\n",
        "        \n",
        "        lemmatized_text.append(lemmatizer.lemmatize(word, get_word_pos(word)))\n",
        "\n",
        "    return \" \".join(lemmatized_text)"
      ],
      "metadata": {
        "id": "pZBK8ccRX_Sk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x : lemmatize(x))\n",
        "test['text'] = test['text'].apply(lambda x : lemmatize(x))"
      ],
      "metadata": {
        "id": "5PZkcVnoX_UY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train['text'].copy()\n",
        "x_test = test['text'].copy()\n",
        "\n",
        "y_train = train['label'].copy()\n",
        "y_test = test['label'].copy()"
      ],
      "metadata": {
        "id": "LfQ6efFhX_XL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umoTZTSXX_ZI",
        "outputId": "dd9c9a33-96d8-4e9e-d7b4-23f00351d269"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    grow b watch love thunderbird mate school watc...\n",
              "1    put movie dvd player coke chip expectation hop...\n",
              "2    people know particular time past like feel nee...\n",
              "3    even though great interest biblical movie bore...\n",
              "4    im die hard dad army fan nothing ever change g...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train: \",x_train.shape,y_train.shape,\"Test: \",(x_test.shape,y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7QjSCuAX_bI",
        "outputId": "36d2b4cc-b888-4c77-9d48-9f7b49288b18"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:  (40000,) (40000,) Test:  ((5000,), (5000,))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing TfidVectorizer"
      ],
      "metadata": {
        "id": "5w-uI9BUHboq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Term frequency-inverse document frequency is a text vectorizer that transforms the text into a usable vector\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
        "tfidfconverter = TfidfVectorizer(max_features=4000, min_df=1, max_df=0.9, ngram_range=(1,1))  \n",
        "X_train = tfidfconverter.fit_transform(x_train)\n",
        "X_test = tfidfconverter.transform(x_test)"
      ],
      "metadata": {
        "id": "yo0gH_6HX_dq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing classification models"
      ],
      "metadata": {
        "id": "qNrIHp_PHidn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## The objective of a Linear SVC (Support Vector Classifier) is to fit to the data you provide, returning a \"best fit\" hyperplane that divides, or categorizes, your data\n",
        "from sklearn.svm import LinearSVC\n",
        "clf = LinearSVC(random_state=0)"
      ],
      "metadata": {
        "id": "pE4NWNB6X_fU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwUQWi2Bi_lk",
        "outputId": "c1ae8cac-bf17-47b9-9c81-390ad625f659"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred=clf.predict(X_test)"
      ],
      "metadata": {
        "id": "HMtetLLki_08"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        " \n",
        "print(confusion_matrix(y_test,y_test_pred))  \n",
        "print(classification_report(y_test,y_test_pred))  \n",
        "print(accuracy_score(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECFj8JV_i_3n",
        "outputId": "1dc0650e-e036-4336-81c0-911e05f52533"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2172  323]\n",
            " [ 269 2236]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88      2495\n",
            "           1       0.87      0.89      0.88      2505\n",
            "\n",
            "    accuracy                           0.88      5000\n",
            "   macro avg       0.88      0.88      0.88      5000\n",
            "weighted avg       0.88      0.88      0.88      5000\n",
            "\n",
            "0.8816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)  \n",
        "text_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlcoLFQ7i_5v",
        "outputId": "1a9381ca-ca16-4132-9e5f-196d69823b67"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = text_classifier.predict(X_test)\n",
        " \n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        " \n",
        "print(confusion_matrix(y_test,predictions))  \n",
        "print(classification_report(y_test,predictions))  \n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax_gu8mOi_8H",
        "outputId": "accae88c-94fa-4e58-b628-ac39e1173b21"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2130  365]\n",
            " [ 364 2141]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85      2495\n",
            "           1       0.85      0.85      0.85      2505\n",
            "\n",
            "    accuracy                           0.85      5000\n",
            "   macro avg       0.85      0.85      0.85      5000\n",
            "weighted avg       0.85      0.85      0.85      5000\n",
            "\n",
            "0.8542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Logistic regression is a process of modeling the probability of a discrete outcome given an input variable\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(max_iter=3500,solver='saga')"
      ],
      "metadata": {
        "id": "UXJuMfxPi_-T"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI7mJOYejAAE",
        "outputId": "bb8fab6c-792a-464a-a75e-e1c1bc6ceb2c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=3500, solver='saga')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred=clf.predict(X_test)"
      ],
      "metadata": {
        "id": "wjTOLzyxjACL"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test,y_test_pred))  \n",
        "print(classification_report(y_test,y_test_pred))  \n",
        "print(accuracy_score(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV5suZHBjAFm",
        "outputId": "27a68e2f-76e5-4a13-9837-92ea44c5dc84"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2172  323]\n",
            " [ 269 2236]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88      2495\n",
            "           1       0.87      0.89      0.88      2505\n",
            "\n",
            "    accuracy                           0.88      5000\n",
            "   macro avg       0.88      0.88      0.88      5000\n",
            "weighted avg       0.88      0.88      0.88      5000\n",
            "\n",
            "0.8816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d_yoH4zAjVh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iNwOiMqYjVj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Lk6odCmnjVl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6MYjQNWfjVpa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}